<!doctype html>
<html>

<!-- TODO
Add links "decoration-amber-500"
Icons under name
Resize canvas onResize
Polygon images DR and DA
Carousel
-->

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="module" src="js/main.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    // tailwind.config = {
    //   theme: {
    //     extend: {
    //       fontFamily: {
    //     kanit: ['Proxima Nova', 'sans-serif'],
    //   },
    //     }
    //   }
    // }
  </script>

  <style type="text/tailwindcss">
    .main-title {
      @apply bg-gradient-to-r from-purple-600 to-pink-400 bg-clip-text text-transparent;
    }
    .section-title {
      @apply text-3xl md:text-5xl p-6 font-bold flex items-center justify-center bg-gradient-to-r from-pink-600 to-purple-500 bg-clip-text text-transparent;
    }
    .p-text {
      @apply text-xl lg:text-3xl;
    }
    .gradient-1 {
      @apply bg-[conic-gradient(at_bottom_left,_var(--tw-gradient-stops))] from-fuchsia-300 via-green-400 to-rose-700;
    }
    .separator {
      @apply my-12 h-px border-t-0 bg-transparent bg-gradient-to-r from-transparent via-pink-600 to-transparent opacity-70;
    }
    .gradient-publications {
      @apply bg-gradient-to-b from-white via-pink-300 to-purple-400;
    }
  </style>
</head>

<body>

  <div id="title" class="min-h-full gradient-1 pt-10">
    <canvas id="c" class="h-full w-full z-0 -mt-10 absolute"></canvas>
    <div
      class="bg-white mx-5 p-5 opacity-90 rounded-md z-50 sm:px-5 md:mx-16 md:px-32 lg:mx-48 lg:px-40 xl:mx-60 2xl:mx-72">
      <h1 class="main-title tracking-tighter text-4xl text-center font-semibold sm:text-5xl xl:text-6xl 2xl:text-7xl">
        Exploring Synthetic Image Generation for Training Computer Vision Models under Data Scarcity</h1>
    </div>
    <h2 class="text-4xl pt-16 sm:pt-32 text-center text-slate-900">a PhD thesis by <br><span class="font-bold">Enric
        Moreu</span>
    </h2>
    <div class="text-center pt-32 pb-5 z-50 opacity-95">
      <button class="md:text-xl bg-pink-500 hover:bg-pink-700 text-white font-semibold py-2 px-4 rounded text-center">
        Download thesis (50MB)
      </button>
    </div>

  </div>

  <div id="abstract" class="min-h-fit bg-white">
    <div class="grid grid-cols-1 lg:grid-cols-2">

      <div class="p-6 text-slate-900 md:text-3xl text-left lg:w-3/4 lg:ml-32 xl:text-4xl">
        <p class="p-text">The utilization of synthetic data in computer vision tasks is subject to certain limitations
          primarily attributed to the occurrence of the domain shift. This phenomenon arises when the distribution of
          data in the training set diverges from that in the test set. Synthetic data, being generated under controlled
          circumstances, possesses a dissimilar distribution compared to real-world data. Consequently, computer vision
          models that are trained on synthetic data exhibit a biased understanding of the target domain, hampering their
          ability to effectively generalize.
        </p>

      </div>
      <img class="m-10 w-5/6 aspect-[1/1] object-cover rounded-lg mx-auto
      sm:w-3/6
      lg:w-4/6
      xl:aspect-[2/1]
      xl:w-5/6
      " src="images/crowd.png" />

    </div>
  </div>
  </div>

  <hr class="separator" />


  <div id="domain-randomization" class="min-h-fit">
    <h1 class="section-title">Domain randomization</h1>

    <div class="mx-5 lg:mx-28 xl:mx-56">
      <img class="w-4/6 pt-2 float-left aspect-[1/1] rounded-lg  object-cover mr-6
      [clip-path:circle(70%_at_20%_30%)]
      [shape-outside:circle(70%_at_20%_30%)]
      md:[clip-path:polygon(0%_0%,100%_0%,75%_100%,0%_100%)]
      md:[shape-outside:polygon(0%_0%,100%_0%,75%_100%,0%_100%)]
      md:w-8/12
      md:aspect-[2/1]
      2xl:[clip-path:polygon(0%_0%,100%_0%,75%_100%,0%_100%)]
      2xl:[shape-outside:polygon(0%_0%,100%_0%,75%_100%,0%_100%)]
      2xl:w-10/12
      2xl:aspect-[2/1]

      " src="images/crowd.png" />
      <p class="p-text">
        Domain randomization is a strategy utilized to alleviate the challenges posed by domain shift. This technique
        involves introducing variations in object textures, background images, and lighting conditions within a semantic
        segmentation task. The underlying goal of domain randomization is to generate a diverse set of synthetic data
        that encompasses a wide range of variations. By exposing the model to these varied environments during training,
        it becomes capable of perceiving real-world data as merely another variation, even if some of the synthetic
        variations may seem unrealistic to human observers.
      </p>
    </div>

  </div>


  <hr class="separator" />


  <div id="domain-adaptation" class="min-h-fit">
    <h1 class="section-title">Domain adaptation</h1>
    <div class="mx-5 lg:mx-28 xl:mx-56">
      <img class="w-3/6 pt-2 float-right aspect-[1/1] rounded-lg  object-cover mr-6
      [clip-path:circle(70%_at_70%_20%)]
      [shape-outside:circle(70%_at_70%_20%)]
      md:[clip-path:polygon(0%_0%,100%_0%,100%_100%,25%_100%)]
      md:[shape-outside:polygon(0%_0%,100%_0%,100%_100%,25%_100%)]
      md:w-6/12
      md:aspect-[2/1]
      2xl:[clip-path:polygon(0%_0%,100%_0%,100%_100%,25%_100%)]
      2xl:[shape-outside:polygon(0%_0%,100%_0%,100%_100%,25%_100%)]
      2xl:w-10/12
      2xl:aspect-[2/1]

      " src="images/crowd.png" />
      <p class="p-text">
        Unlike domain randomization, domain adaptation aims to make the data more realistic by minimising the gap
        between the source domain and the target domain. Techniques like feature alignment and adversarial learning can
        be used for adaptation. By leveraging these approaches and synthetic data, models can adapt their knowledge and
        perform well in target domains. This approach has been shown to be effective in reducing the domain gap,
        especially when there is limited labeled data in the target domain.
      </p>
    </div>
  </div>

  <hr class="separator" />


  <div id="publications" class="min-h-full">
    <h1 class="section-title">List of publications</h1>
    <div class="p-6 text-lg md:px-40 xl:scroll-px-96 xl:text-2xl">
      <ul class="space-y-5 text-slate-900 list-decimal list-inside p-text">
        <li>
          <strong>Enric Moreu*</strong>, Eric Arazo*, Kevin McGuinness, Noel E. O’Connor. <i class="decoration-pink-600 underline">“Self-Supervised and
            Semi-Supervised Polyp Segmentation using Synthetic Data”</i>. In <i>International Joint Conference on Neural Networks (IJCNN)</i>.
          June 2023.
        </li>
        <li>
          <strong>Enric Moreu</strong>, Alex Martinelli, Martina Naughton, Philip Kelly, Noel E. O’Connor. <i class="decoration-pink-600 underline">“Fashion CUT: Unsupervised
          domain adaptation for visual pattern classification in clothes using synthetic data and pseudo-labels”</i>. In
          <i>Scandinavian Conference on Image Analysis (SCIA)</i>. April 2023.
        </li>
        <li>
          <strong>Enric Moreu</strong>, Eric Arazo, Kevin McGuinness, Noel E. O’Connor. <i class="decoration-pink-600 underline">“Joint one-sided synthetic unpaired image
          translation and segmentation for colorectal cancer prevention”</i>. In <i>Expert Systems, e13137</i>. September 2022.
        </li>
        <li>
          <strong>Enric Moreu</strong>, Diego Ortego, Kevin McGuinness, Noel E. O’Connor. <i class="decoration-pink-600 underline">“Domain Randomization for Object Counting”</i>.
          In <i>Irish Conference on Artificial Intelligence and Cognitive Science (AICS)</i>. December 2021.

        </li>
        <li>
          <strong>Enric Moreu</strong>, Kevin McGuinness, Noel E. O’Connor. <i class="decoration-pink-600 underline">“Synthetic data for unsupervised polyp segmentation”</i>. In
          <i>Irish Conference on Artificial Intelligence and Cognitive Science (AICS)</i>. December 2021.
        </li>
      </ul>
    </div>
  </div>

</body>

</html>